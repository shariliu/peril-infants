---
title: "Dangerous ground: Thirteen-month-old infants are sensitive to peril in other peopleâ€™s actions "
author: "Shari Liu"
date: "October 12, 2021"
output:
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = "##", echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE, include=FALSE, dependson="wide")
options(scipen = 0, digits = 3)

## load required packages
ipak <- function (pkg) {
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

# devtools::install_github("mhtess/rwebppl")

packages <- c("tidyverse", "Hmisc", "lattice", "multcomp", "lsmeans", "schoRsch", "influence.ME", "lme4", "effects", "lmerTest", "cowplot", "irr", "simr", "plyr", "dplyr", "HLMdiag", "wesanderson", "patchwork", "janitor")
ipak(packages)

detach("package:dplyr", unload = TRUE)
library(dplyr)


```

```{r prep.data}

# read in data
wide <- read.csv(file = "peril_data_deid.csv", header = TRUE) 
head(wide)
str(wide)

# convert into long format
long <- gather(wide, type, look, testavg_lower:control_deep) 
str(long)

# log transform looks
long$look <- as.numeric(as.character(long$look))
long$loglook <- log(long$look)

# set levels for different kinds of looks
long$type <- factor(long$type)
#levels(long$type) <- c("Higher",
                       # "Lower", 
                       # "Deep (Control)",
                       # "Shallow (Control)",
                       # "Higher 1",
                       # "Higher 2",
                       # "Lower 1",
                       # "Lower 2",
                       # "Binary Pref",
                       # "Proportion Higher",
                       # "Proportion Lower")

# subset averaged looks across test pairs (2 observations per participant) and control events
long.avg <- long %>% 
  filter(type == "testavg_higher" | type == "testavg_lower" | type == "control_deep" | type =="control_shallow") %>%
  separate(type, into=c("phase", "type"), sep="_")%>%
  # add age groups (relevant for Experiments 1-3)
  mutate(agegroup = as.factor(case_when(agem < 12 ~ "younger",
                            agem > 12 ~ "older")))

long.avg$type <- factor(long.avg$type)

long.avg$sex <- relevel(as.factor(long.avg$sex), ref = "m")

exp1.avg <-dplyr::filter(long.avg, exp == "Exp.1" & phase == "testavg")
exp2.avg <-dplyr::filter(long.avg, exp == "Exp.2")
exp3.avg <-dplyr::filter(long.avg, exp == "Exp.3")
luts.exp3 <- dplyr::filter(long.avg, experiment == "LUTS.Exp.3")

risk.avg <- long.avg %>%
  filter(cost == "Risk",
         agegroup == "older") %>%
  mutate(task = as.factor(
    case_when(experiment == "RISK13" ~ "infer.value",
              (experiment == "MR13" | experiment == "MR2") ~ "min.risk")))

op <- options(contrasts = c("contr.treatment", "contr.poly")) # treatment contrasts
```


```{r prep.functions}
# function for identifying influential observations, and then returning a new model without them
# INPUTS: model = model name, data = dataset, and subj = column heading for observations
# OUTPUT: model excluding influential subjects
exclude.cooks <- function(model, data, subj) {
  cooks <- cooks.distance(influence(model, subj))
  cutoff <- 4/length(unique(data$subj))
  new.model <- exclude.influence(model, grouping = subj, level=data[which(cooks > cutoff),]$subj)
  return(new.model)
}

# function that computes CIs and returns them in df
gen.ci <- function(model) {
  df <- data.frame(confint(model))
  names(df) <- c("lower", "upper")
  return(df)
}

# function that converts model summary to df
gen.m <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "df", "t", "p")
  return(df)
}

# function that returns age info and number of females in a dataset, assuming 2 rows of data per subj
info <- function(longdata) {
  longdata %>% summarize(mean = mean(agem), min=range(agem)[1], max=range(agem)[2], f=sum(sex=="f")/2, n=length(unique(subj)))
}

## Retrieved from : http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/#error-bars-for-within-subjects-variables
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=TRUE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column    
  datac <- plyr::rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}
## Norms the data within specified groups in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=TRUE, .drop=TRUE) {
  library(plyr)
  
  # Measure var on left, idvar + between vars on right of formula.
  data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                         .fun = function(xx, col, na.rm) {
                           c(subjMean = mean(xx[,col], na.rm=na.rm))
                         },
                         measurevar,
                         na.rm
  )
  
  # Put the subject means with original data
  data <- merge(data, data.subjMean)
  
  # Get the normalized data in a new column
  measureNormedVar <- paste(measurevar, "_norm", sep="")
  data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
    mean(data[,measurevar], na.rm=na.rm)
  
  # Remove this subject mean column
  data$subjMean <- NULL
  
  return(data)
}

## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=TRUE, conf.interval=.95, .drop=TRUE) {
  
  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                       FUN=is.factor, FUN.VALUE=logical(1))
  
  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }
  
  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL
  
  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
  
  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")
  
  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                  FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
  
  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor
  
  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

# function that returns ICC 
reporticc <- function(output, places) {
  mainstat <- output$value
  upperci <- output$ubound
  lowerci <- output$lbound
  statistic <- paste("ICC=", round(mainstat,places), ", 95% CI [", round(lowerci, places), ", ", round(upperci, places), "]", sep = "")
  return(statistic)
}

# function that returns column of standardized betas from lmer model
gen.beta <- function(model) {
  f <- data.frame(fixef(model))
  colnames(f) <- "beta"
  return(f)
}

# function that computes CIs and returns them in df
gen.ci <- function(model) {
  df <- data.frame(confint(model))
  names(df) <- c("lower", "upper")
  return(df)
}

# function that converts model summary (lmer) to df
gen.m <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "df", "t", "p")
  return(df)
}

# function that converts model summary (lm) to df
gen.lm <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "t", "p")
  return(df)
}

# function that returns APA-formatted result from lme4/lmerTest table
report <- function(table, index, places, tails, flip) {
  if (tails == "1") {
    p <- round(table$p[index], places)/2
    howmanytails <- "one-tailed"
  } else {
    p <- round(table$p[index], places)
    howmanytails <- "two-tailed"
  }
  if (p < .001) {
    p <- "<.001"
  } else {
    p <- paste("=", round(p, places), sep = "")
  }
  if (missing(flip)) {
    result <- paste("[", round(table$lower[index], places), ",", round(table$upper[index], places), "], ÃŸ=", round(table$beta[index], places), ", B=", round(table$est[index],places), ", SE=", round(table$se[index],places), ", p", p, ", ", howmanytails, sep = "")
  } else {
    result <- paste("[", -round(table$upper[index], places), ",", -round(table$lower[index], places), "], ÃŸ=", -round(table$beta[index], places), ", B=", -round(table$est[index],places), ", SE=", round(table$se[index],places), ", p", p, ", ", howmanytails, sep = "")
  }
  return(result)
}
```

```{r summary}
## get within-subjects CIs for plotting

# warning about Nan has to do with missing observations for control events
summary.avg <- summarySEwithin(data = risk.avg, measurevar = "look", betweenvars = c("exp", "phase"), withinvars = "type", idvar = "subj") %>%
  drop_na() %>%  
  mutate(cliff = type)
levels(summary.avg$cliff) <- c("deep", "deep", "shallow", "shallow")
levels(summary.avg$phase) <- c("control", "test")

```

```{r ntrialsexcluded}

# figure out how many looks are missing from the dataframe
nexclude <- wide %>%
   gather(type, look, control_1:test4) %>%
   filter(cost=="Risk") %>%
   mutate(missing = case_when(is.na(look) | str_detect(look, "NA") ~ 1)) %>%
   group_by(exp) %>%
   count(missing) %>%
  filter(!is.na(missing)) %>%
  rename(n_missing = n) %>%
  select(!missing)

# TODO double check this - seems like too small a number

totaltrials <- wide %>%
   gather(type, look, control_1:test4) %>%
   filter(cost=="Risk",
          !is.na(experiment)) %>%
   group_by(exp) %>%
   tally() %>%
   dplyr::rename(total = n)

ntrials <- full_join(nexclude, totaltrials)
```


## Reliability + Distribution Info
```{r reliability}

rel <- read.csv(file = "peril_reliability_deid.csv", header=TRUE)
exp1 <- rel %>% filter(experiment.new=="Exp.1")
exp2 <- rel %>% filter(experiment.new=="Exp.2")
exp3 <- rel %>% filter(experiment.new=="Exp.3")

exp1rel <- icc(data.frame(exp1$secondary.look, exp1$orig.look),model="one", type="agreement")

exp2rel <- icc(data.frame(exp2$secondary.look, exp2$orig.look),model="one", type="agreement")

exp3rel <- icc(data.frame(exp3$secondary.look, exp3$orig.look),model="one", type="agreement")

```

```{r log, include = TRUE}
normal.ll <- fitdistr(na.omit(risk.avg$look), "normal")$loglik
lognormal.ll <- fitdistr(na.omit(risk.avg$look), "lognormal")$loglik
```

# Figures

```{r fig.exp1, include=TRUE, fig.width=8}

theme_set(theme_cowplot(font_size=20))

exp1.fig.data <- risk.avg %>% filter(task == "infer.value",
                                           phase == "testavg")
levels(exp1.fig.data$type) <- c(NA, "higher", "lower", NA)
exp1.fig.data$type <- relevel(exp1.fig.data$type, ref = "higher")
colors1 <- c(wes_palettes$Zissou1[3], wes_palettes$Zissou1[2])

risk1 <- ggplot(data = exp1.fig.data %>% filter(exp=="Exp.1"), aes(type, look, fill = type))+
  geom_boxplot()+
  scale_fill_manual(values=colors1)+
    geom_errorbar(data = summary.avg %>% filter(exp =="Exp.1"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  ylab("Looking Time (s)") +
  xlab("Test event") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  theme(legend.position="none")+
  scale_x_discrete(labels = c("higher\nvalue", "lower\nvalue"))
  # annotate("text", colour="red", x=1.5, y=63, size=5, label=c("*ÃŸ=0.354", "ÃŸ=0.168")) +
  # facet_wrap(~exp, scales = "fixed", drop=TRUE)
  # theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

risk1
```

**Figure 3.** Looking time towards the test events presenting approaches to the goals attained through actions of higher vs. lower peril in Experiments 1-2, both (A) within and (B) collapsed across experiments.  Red error bars around means indicate within-subjects 95% confidence intervals. Pairs of points indicate data from a single participant. Horizontal bars within boxes indicate medians, and boxes indicate the middle 2 quartiles of data.  Beta coefficients (ÃŸ) indicate effect sizes in standard deviations.

```{r fig.exp2, include=TRUE, fig.width=10, fig.height=16}

exp23.figure <- rbind(exp2.avg,exp3.avg) %>%
  filter(agegroup == "older") %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))
exp23.figure$cliff <- as.factor(exp23.figure$cliff)
exp23.figure$cliff <- relevel(exp23.figure$cliff, ref = "shallow")
exp23.figure$phase <- as.factor(exp23.figure$phase)

levels(exp23.figure$cliff)
levels(exp23.figure$phase) <- c("control", "test")
exp23.colors <- c(wes_palette("Royal2")[2], wes_palette("Royal2")[1])

exp2.figure <- ggplot(data = exp23.figure %>% filter(exp == "Exp.2"), aes(cliff, look, fill = cliff)) +
  geom_boxplot(aes(alpha=phase))+
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  geom_errorbar(data = summary.avg %>% filter(exp == "Exp.2"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  ylab("Looking Time (s)") +
  xlab("Cliff Depth") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  facet_wrap(~phase, nrow=1)+
  theme(legend.position="none")+
  scale_fill_manual(values = exp23.colors)+
  scale_alpha_discrete(range=c(0.4, 1))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

exp3.figure <- ggplot(data = exp23.figure %>% filter(exp == "Exp.3"), aes(cliff, look, fill = cliff)) +
  geom_boxplot(aes(alpha=phase))+
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  geom_errorbar(data = summary.avg %>% filter(exp == "Exp.3"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  ylab("Looking Time (s)") +
  xlab("Cliff Depth") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  facet_wrap(~phase, nrow=1)+
  theme(legend.position="none")+
  scale_fill_manual(values = exp23.colors)+
  scale_alpha_discrete(range=c(0.4, 1))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


exp2.figure + exp3.figure + plot_annotation(tag_levels = 'A')

```

**Figure 4.**  Looking times from Experiment during the test events, in which the agent chose to jump across a deeper or shallower trench for a goal (A and B), and during the control events, in which infantsâ€™ attention was drawn over the deeper and shallower trenches (C and D). The looking times are presented by separately (A and C) and collapsed across age groups (B and D). Red error bars around means indicate within-subjects 95% confidence intervals. Pairs of points indicate data from a single participant. Horizontal bars within boxes indicate medians, and boxes indicate the middle 2 quartiles of data. Beta coefficients (ÃŸ) list effect sizes in standard deviations.


# Experiment 1: Inferring value from risk

```{r exp1.primary}
exp1.avg$type <- relevel(exp1.avg$type, ref = "higher")


exp1.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp1.avg)

exp1.1 <- lmer(loglook ~ type + (1|subj),
               data = exp1.avg)

# id influential observations
plot(influence(exp1.1, "subj"), which="cook",
     cutoff=4/32, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp1.1.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp1.avg %>% filter(subj != "S4_12"))

exp1.1.table <- gen.m(exp1.1)
exp1.1.ci <- gen.ci(exp1.1)[3:4,]

exp1.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp1.avg)
exp1.1.betas <- gen.beta(exp1.1.beta)

exp1.results <- cbind(exp1.1.table, exp1.1.betas,exp1.1.ci)


```

## Methods

### Participants
Our final sample of participants included N=`r info(exp1.avg)$n` 13-month-old infants (M=`r info(exp1.avg)$mean` months, range=`r info(exp1.avg)$min`-`r info(exp1.avg)$max`, `r info(exp1.avg)$f` female). Seven infants were excluded and replaced due to fussiness (3 infants) or inattentiveness during test trials (4 infants). All data were collected at the Harvard Lab for Developmental Studies with procedures approved by the Committee on the Protection of Human Subjects. The methods, sample size, hypotheses, and analyses were pre-registered at https://osf.io/bs3e7/. We chose to study 13-month-old infants in Experiment 1 because younger infants were not available at the time the study began, and because 13-month-old infants have more experience with standing, walking, and falling: experiences that may be important for the development of these abilities (Kretch & Adolph, 2013). 

### Data Coding and Analysis Strategy.
All experimenters and coders were naive to the nature and the order of the test events and were unable to see what the babies saw during the experiment (they relied on trial-neutral sound cues to start each trial). To check for exclusions and coding errors, all test trial data were re-coded in Datavyu and excluded as necessary: If an infant looked away from a test event without ever having seen the agent jump, or if the trial ended too early or late, that trial was marked and excluded from subsequent analysis (`r ntrials$n_missing[1]` out of `r ntrials$total[1]` total test trials). We used these offline coded looking times for our final analyses. To assess the reliability of the data, 50% of test trials from the experiment (`r ntrials$total[1]/2` out of `r ntrials$total[1]` trials) were re-coded Datavyu by an additional researcher who was naive to test event order. Reliability was high, `r reporticc(exp1rel,3)`.  All decisions to include or exclude trials or participants from our analysis were made by researchers who were blind to the events seen by infants.

Infant looking times are often log-normally distributed (Csibra, Hernik, Mascaro, Tatone, & Lengyel, 2016), including in this dataset (log-likelihood of data for Experiments 1-4 under normal distribution = `r normal.ll`, under lognormal distribution = `r lognormal.ll`), so our pre-registered dependent measure was the average looking time towards the higher- or lower-danger choice at test in log seconds, and the values of unstandardized B coefficients and 95% confidence intervals are reported in this unit. Nevertheless, we include summary statistics and plots of untransformed looking times for interpretability. We analyzed all looking times using mixed effects models (Bates, MÃ¤chler, Bolker, & Walker, 2015) implemented in R. All analyses including repeated measures included a random intercept for participant identity. Analyses conducted over multiple experiments included a random intercept for experiment, except in one case where including this intercept lead to issues with convergence. For every model, we checked for influential participants using Cookâ€™s Distance (Nieuwenhuis, te Grotenhuis, & Pelzer, 2012) and excluded any participants who exceeded the standard 4/n threshold, where n is the number of participants. The number of participants that met this criterion is listed in every model result. 

## Results
### Pre-registered results.
We compared infantsâ€™ looking times when the agent approached the target for which it performed the more dangerous action (Higher Value) to the looking times when the agent approached the other target (Lower Value). Thirteen-month-old infants looked longer when the agent chose the target achieved through the lower-danger action (Mlower=`r summary.1013$look[2]`s (SE `r summary.1013$sd[2]`), Mhigher=`r summary.1013$look[1]`s (SE `r summary.1013$sd[1]`), 95% confidence interval (CI) over difference in log seconds `r report(exp1.results,2,3,2)` excluding one influential participant). This looking preference is consistent with the interpretation that infants expected the agent to choose the target for which it had undertaken a more dangerous action and looked longer when this expected outcome did not occur. 

# Experiment 2: Minimizing Risk
```{r exp2.primary}

exp2.test <- exp2.avg %>% filter(phase=="testavg") 

exp2.info <- info(exp2.avg)

exp2.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp2.test)

exp2.1 <- lmer(loglook ~ type + (1|subj),
               data = exp2.test)

# id influential observations
plot(influence(exp2.1, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# one influential observation

exp2.1.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp2.test %>% filter(subj != "24-MR"))
exp2.1.table <- gen.m(exp2.1.cooks)
exp2.1.ci <- gen.ci(exp2.1.cooks)[3:4,]

exp2.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp2.test %>% filter(subj != "24-MR"))
exp2.1.betas <- gen.beta(exp2.1.beta)

exp2.results <- cbind(exp2.1.table, exp2.1.betas, exp2.1.ci)
```

```{r exp2.pre}
exp2.control <- exp2.avg %>% filter(phase=="control") 

exp2.2 <- lmer(loglook ~ type + (1|subj),
               data = exp2.control)

# id influential observations
plot(influence(exp2.2, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# two influential observation

exp2.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp2.control %>% filter(subj != "59-MR" & subj != "54-MR"))

exp2.table <- gen.m(exp2.cooks)
exp2.ci <- gen.ci(exp2.cooks)[3:4,]

exp2.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp2.control %>% filter(subj != "59-MR" & subj != "54-MR"))
exp2.betas <- gen.beta(exp2.beta)

exp2.results2 <- cbind(exp2.2.table, exp2.2.betas, exp2.2.ci)
```

```{r exp2.pre.vs.test}
exp2.control.test <- exp2.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))

  
exp2.control.test$type <- as.factor(exp2.control.test$type)

exp2.3 <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp2.control.test)

plot(influence(exp2.3, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# 1 influential observation

exp2.3.cooks <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp2.control.test)

exp2.3.table <- gen.m(exp2.3)
exp2.3.ci <- gen.ci(exp2.3)[3:6,]

exp2.3.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj),
                     data = exp2.control.test)
exp2.3.betas <- gen.beta(exp2.3.beta)

exp2.results3 <- cbind(exp2.3.table,exp2.3.betas,exp2.3.ci)
```

# Experiment 3: Minimizing risk replication (no shattering)
```{r exp3.pre.vs.test}
exp3.control.test <- exp3.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))

  
exp3.control.test$type <- as.factor(exp3.control.test$type)

exp3.3 <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp3.control.test)

plot(influence(exp3.3, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# no influential observations 

exp3.3.cooks <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp3.control.test %>% filter(subj != "28"))

exp3.3.table <- gen.m(exp3.3.cooks)
exp3.3.ci <- gen.ci(exp3.3.cooks)[3:6,]

exp3.3.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj),
                     data = exp3.control.test %>% filter(subj != "28"))
exp3.3.betas <- gen.beta(exp3.3.beta)

exp3.results3 <- cbind(exp3.3.table,exp3.3.betas,exp3.3.ci)

pairwise <- lsmeans(exp3.3.cooks, list(pairwise~cliff|phase))

pairwise[[2]][1]
```


```{r exp3.test}
exp3.avg <- exp3.avg %>% filter(phase=="testavg") 

exp3.info <- info(exp3.avg)

exp3.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp3.avg)

exp3.1 <- lmer(loglook ~ type + (1|subj),
               data = exp3.avg)

# id influential observations
plot(influence(exp3.1, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# no influential observations

exp3.1.table <- gen.m(exp3.1)
exp3.1.ci <- gen.ci(exp3.1)[3:4,]

exp3.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp3.avg)
exp3.1.betas <- gen.beta(exp3.1.beta)

exp3.results <- cbind(exp3.1.table, exp3.1.betas, exp3.1.ci)
```

## Methods
### Participants
Our final sample of participants included N=`r exp3a.info$n` 10-month-old infants (M=`r exp3a.info$mean` months, range=`r exp3a.info$min`-`r exp3a.info$max`, `r exp3a.info$f` female) and N=`r exp3b.info$n` 13-month-old infants (M=`r exp3b.info$mean` months, range=`r exp3b.info$min`-`r exp3b.info$max`, `r exp3b.info$f` female). We chose this sample size using a power analysis from a pilot study (effect size ÃŸ=0.323), as well as estimates of effect sizes of studies with similar displays and design (Liu & Spelke, 2017; Liu et al., 2017). Eight infants were excluded and replaced in the final sample due to fussiness (3 infants), inattentiveness during test trials (3 infants), or interference from caregivers (2 infants). The methods, sample size, hypotheses, and analyses of this experiment were pre-registered and open access at https://osf.io/kx928/.

### Data Coding and Analysis
The data coding and analysis strategy for Experiment 3 were identical to those of Experiments 1 and 2. Thirty-nine out of `r ntrials$total[3]` total trials (4 test trials and 2 control trials per participant) were excluded from the analysis based on inattentiveness or coding error. To assess the reliability of the data, 50% of test trials from the experiment (`r ntrials$total[3]/2` of `r ntrials$total[3]` total test trials) were re-coded Datavyu by an additional researcher who was naive to test event order. Reliability was high, `r reporticc(exp3rel,3)`.

## Results
### Pre-registered results
Across both age groups, infants looked longer at test when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[7]`s (SD=`r summary.avg$sd[7]`), Mshallow=`r summary.avg$look[8]`s (SD=`r summary.avg$sd[8]`), `r report(exp3.results0,2,3,1)`, excluding one influential participant). See Figure 5.

### Comparing test events to control events
To test whether this looking preference reflected the relative danger of the different jumps, or other perceptual features of the shallow and deep trenches, we compared infantsâ€™ looking times during the control events, where their attention was drawn to each trench using an attention-getting star that was placed in the path of the agentâ€™s subsequent actions. We found that infants showed a preference for the shallower trench in this context (Mdeep=`r summary.avg$look[5]`s (SD=`r summary.avg$sd[5]`), Mshallow=`r summary.avg$look[6]`s (SD=`r summary.avg$sd[6]`), `r report(exp3.results2,2,3,2)`, excluding 2 influential participants). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp3.results3,4,3,2)`). Thus, infantsâ€™ expectations at test cannot be due to an intrinsic preference for events occurring over deeper to those over shallower trenches.

### Exploring age differences
#### Results in 13-month-old infants
Thirteen-month-old infants looked longer at test when the agent, at test, chose the deeper trench over the shallower trench (Mdeep=`r summary.1013$look[11]`s (SD=`r summary.1013$sd[11]`), Mshallow=`r summary.1013$look[12]`s (SD=`r summary.1013$sd[12]`), 
`r report(exp3b.results, 2, 3, 1)`, excluding one influential participant. During control events, 13-month-old infants preferred to look at the shallow trench (Mdeep=`r summary.1013$look[9]`s (SD=`r summary.1013$sd[9]`), Mshallow=`r summary.1013$look[10]`s (SD=`r summary.1013$sd[10]`), `r report(exp3b.results2,2,3,2)`, excluding 2 influential participants). Their looking preferences significantly differed across the two conditions, `r report(exp3b.results3,4,3,2)`, two-tailed. 

#### Results in 10-month-old infants

Ten-month-old looked longer at test when the agent chose the deeper the shallower trench (Mdeep=`r summary.1013$look[7]`s (SD=`r summary.1013$sd[7]`), Mshallow=`r summary.1013$look[8]`s (SD=`r summary.1013$sd[8]`), `r report(exp3a.results,2,3,1)`, excluding one influential participant. During control events, 10-month-old infants displayed no strong looking preference (Mdeep=`r summary.1013$look[5]`s (SD=`r summary.1013$sd[5]`), Mshallow=`r summary.1013$look[6]`s (SD=`r summary.1013$sd[6]`), `r report(exp3a.results2,2,3,2)`, excluding 1 influential participant). In contrast to the data from the 13-month-old infants, however, these two patterns of looking preference did not differ from each other, `r report(exp3a.results3,4,3,2)`.

#### Comparing 10-month-old and 13-month-old infants

The two groups of infants did not differ in their looking preferences between the two test events (`r report(exp3.results, 4, 3, 2)`, excluding one influential participant), or between the two control events (`r report(exp3.results4, 4, 3, 2)`, excluding 2 influential participants).  Infants of the two ages also did not show different looking preferences between the control and test events (`r report(exp3.results5, 8, 3, 2)`). 

# Experiment 4: Replication of Experiment 3 (13-month-old infants)

# Data reliability and coding
To assess the reliability of the data, 50% of test trials from the experiment (`r ntrials$total[4]/2` of `r ntrials$total[4]` total test trials) were re-coded Datavyu by an additional researcher who was naive to test event order. Reliability was high, `r reporticc(exp4rel,3)`.

## Pre-registered Analysis: Long looking to perilous action, different from control actions
```{r}
exp4.avg$type <- relevel(exp4.avg$type, ref = "lower")
exp4.test <- exp4.avg %>% filter(phase == "testavg")


exp4.1 <- lmer(data = exp4.test, 
     formula = loglook ~ type + (1|subj))
summary(exp4.1)
# no influential subjects found
plot(influence(exp4.1, "subj"), which="cook",
     cutoff=4/42, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp4.1.table <- gen.m(exp4.1)
exp4.1.ci <- gen.ci(exp4.1)[3:4,]

exp4.1.beta <- lmer(scale(loglook) ~type + (1|subj),
               data = exp4.test)
exp4.1.betas <- gen.beta(exp4.1.beta)

exp4.1.results <- cbind(exp4.1.table, exp4.1.betas, exp4.1.ci)

```

```{r}
exp4.control.test <- exp4.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))
exp4.control.test$cliff <- as.factor(exp4.control.test$cliff)

exp4.2 <- lmer(data = exp4.control.test, 
     formula = loglook ~ cliff * phase + (1|subj))
summary(exp4.2)

plot(influence(exp4.2, "subj"), which="cook",
     cutoff=4/42, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp4.2.cooks <- lmer(data = exp4.control.test %>% filter(subj != "28" & subj != "26"), 
     formula = loglook ~ cliff * phase + (1|subj))
exp4.2.table <- gen.m(exp4.2.cooks)
exp4.2.ci <- gen.ci(exp4.2.cooks)[3:6,]

exp4.2.beta <- lmer(scale(loglook) ~cliff * phase + (1|subj),
               data = exp4.control.test %>% filter(subj != "28" & subj != "26"))
exp4.2.betas <- gen.beta(exp4.2.beta)

exp4.2.results <- cbind(exp4.2.table, exp4.2.betas, exp4.2.ci)
```

```{r}
exp4.control <- exp4.avg %>%
  filter(phase=="control") %>%
  mutate(cliff = type)

exp4.3 <- lmer(data = exp4.control, 
     formula = loglook ~ cliff + (1|subj))
summary(exp4.3)

plot(influence(exp4.3, "subj"), which="cook",
     cutoff=4/42, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp4.3.cooks <- lmer(data = exp4.control %>%
                       filter(subj != "28",
                              subj != "26"), 
     formula = loglook ~ cliff + (1|subj))
exp.4.3.table <- gen.m(exp4.3.cooks)
exp.4.3.ci <- gen.ci(exp4.3.cooks)[3:4,]

exp4.3.cooks.beta <- lmer(data = exp4.control %>%
                       filter(subj != "28",
                              subj != "26"), 
     formula = scale(loglook) ~ cliff + (1|subj))
exp.4.3.betas <- gen.beta(exp4.3.cooks.beta)

exp.4.3.results <- cbind(exp.4.3.table, exp.4.3.betas, exp.4.3.ci)
```

```{r}
wide %>%
  filter(exp == "Exp.4") %>%
  tabyl(device)

wide %>%
  filter(exp == "Exp.4") %>%
  tabyl(highchair)

wide %>%
  filter(exp == "Exp.4") %>%
  summarise(vquality = mean(video_quality, na.rm=TRUE),
            vquality.sd = sd(video_quality, na.rm=TRUE),
            aquality = mean(audio_quality, na.rm=TRUE),
            aquality.sd = sd(audio_quality, na.rm=TRUE))

# wide %>%
#   filter(exp == "Exp.4") %>%
#   tabyl(chs)

```

### Participants
Our final sample of participants included N=`r info(exp4.avg)$n` 13-month-old infants (M=`r info(exp4.avg)$mean` months, range=`r info(exp4.avg)$min`-`r info(exp4.avg)$max`, `r info(exp4.avg)$f/2` female).

### Pre-registered results
Infants looked longer at test when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[11]`s (SD=`r summary.avg$sd[11]`), Mshallow=`r summary.avg$look[12]`s (SD=`r summary.avg$sd[12]`), `r report(exp4.1.results,2,3,1)`, no influential participants). See Figure x.

### Comparing test events to control events
To test whether this looking preference reflected the relative danger of the different jumps, or other perceptual features of the shallow and deep trenches, we compared infantsâ€™ looking times during the control events, where their attention was drawn to each trench using an attention-getting star that was placed in the path of the agentâ€™s subsequent actions. We found that infants showed a numerical but non-significant preference for the shallower trench in this context (Mdeep=`r summary.avg$look[9]`s (SD=`r summary.avg$sd[9]`), Mshallow=`r summary.avg$look[10]`s (SD=`r summary.avg$sd[10]`), `r report(exp.4.3.results,2,3,2)`, excluding 2 influential participants). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp4.2.results,4,3,2,1)`). 



# Experiment 5: Replication of Experiment 3 (10-month-old infants)
```{r}
exp5.avg$type <- relevel(exp5.avg$type, ref = "lower")
exp5.test <- exp5.avg %>% filter(phase == "testavg")


exp5.1 <- lmer(data = exp5.test, 
     formula = loglook ~ type + (1|subj))
summary(exp5.1)
# 1 influential subject found
plot(influence(exp5.1, "subj"), which="cook",
     cutoff=4/40, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp5.1.cooks <- lmer(data = exp5.test %>% filter(subj != "10m_33"), 
     formula = loglook ~ type + (1|subj))
summary(exp5.1.cooks)

exp5.1.table <- gen.m(exp5.1.cooks)
exp5.1.ci <- gen.ci(exp5.1.cooks)[3:4,]

exp5.1.beta <- lmer(scale(loglook) ~type + (1|subj),
               data = exp5.test %>% filter(subj != "10m_33"))
exp5.1.betas <- gen.beta(exp5.1.beta)

exp5.1.results <- cbind(exp5.1.table, exp5.1.betas, exp5.1.ci)

```

```{r}
exp5.control.test <- exp5.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))
exp5.control.test$cliff <- as.factor(exp5.control.test$cliff)

exp5.2 <- lmer(data = exp5.control.test, 
     formula = loglook ~ cliff * phase + (1|subj))
summary(exp5.2)

# no influential subjects detected
plot(influence(exp5.2, "subj"), which="cook",
     cutoff=4/40, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp5.2.table <- gen.m(exp5.2)
exp5.2.ci <- gen.ci(exp5.2)[3:6,]

exp5.2.beta <- lmer(scale(loglook) ~cliff * phase + (1|subj),
               data = exp5.control.test)
exp5.2.betas <- gen.beta(exp5.2.beta)

exp5.2.results <- cbind(exp5.2.table, exp5.2.betas, exp5.2.ci)
```

```{r}
exp5.control <- exp5.avg %>%
  filter(phase=="control") %>%
  mutate(cliff = type)

exp5.3 <- lmer(data = exp5.control, 
     formula = loglook ~ cliff + (1|subj))
summary(exp5.3)

plot(influence(exp5.3, "subj"), which="cook",
     cutoff=4/40, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp.5.3.table <- gen.m(exp5.3)
exp.5.3.ci <- gen.ci(exp5.3)[3:4,]

exp5.3.beta <- lmer(data = exp5.control,
     formula = scale(loglook) ~ cliff + (1|subj))
exp.5.3.betas <- gen.beta(exp5.3.beta)

exp.5.3.results <- cbind(exp.5.3.table, exp.5.3.betas, exp.5.3.ci)
```

```{r}
wide %>%
  filter(exp == "Exp.5") %>%
  tabyl(device)

wide %>%
  filter(exp == "Exp.5") %>%
  tabyl(highchair)

wide %>%
  filter(exp == "Exp.5") %>%
  summarise(vquality = mean(video_quality, na.rm=TRUE),
            vquality.sd = sd(video_quality, na.rm=TRUE),
            aquality = mean(audio_quality, na.rm=TRUE),
            aquality.sd = sd(audio_quality, na.rm=TRUE))

# wide %>%
#   filter(exp == "Exp.5") %>%
#   tabyl(chs)

```


### Participants
Our final sample of participants included N=`r info(exp5.avg)$n` 10-month-old infants (M=`r info(exp5.avg)$mean` months, range=`r info(exp5.avg)$min`-`r info(exp5.avg)$max`, `r info(exp5.avg)$f/2` female).

### Pre-registered results
Infants looked equally at test when the agent chose to jump the deeper trench vs when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[15]`s (SD=`r summary.avg$sd[15]`), Mshallow=`r summary.avg$look[16]`s (SD=`r summary.avg$sd[16]`), `r report(exp5.1.results,2,3,1)`, excluding 1 influential participant). See Figure x.

### Comparing test events to control events
To test whether this looking preference reflected the relative danger of the different jumps, or other perceptual features of the shallow and deep trenches, we compared infantsâ€™ looking times during the control events, where their attention was drawn to each trench using an attention-getting star that was placed in the path of the agentâ€™s subsequent actions. We found that infants did not show a looking preference across these test events (Mdeep=`r summary.avg$look[13]`s (SD=`r summary.avg$sd[13]`), Mshallow=`r summary.avg$look[14]`s (SD=`r summary.avg$sd[14]`), `r report(exp.5.3.results,2,3,2)`, no influential participants). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp5.2.results,4,3,2,1)`, no influential participants). 

# Supplemental Online Materials

```{r logplot}
# is a lognormal transformation justified given the distribution of looks?
fig.S1 <- ggplot(data = risk.avg, aes(look, fill=exp))
fig.S1 +
  geom_density(alpha = 0.5)+
  # geom_text(aes(experiment))+
  theme_cowplot(20)+
  # facet_wrap(~exp)+
  xlab("Looking Time (s)")
  # scale_fill_brewer(palette="Set2")
```

**Figure S1.** Density plot of looking times during test for Experiments 1 and 2 (total N=`r length(unique(risk.avg$subj))`) from test events and control events. Maximum-likelihood fitting revealed that the lognormal distribution (log likelihood=`r lognormal.ll`) provides a better fit to these data than the normal distribution (log likelihood=`r normal.ll`).

```{r famplot}
fam <- wide %>%
  filter(cost=="Risk",
         (exp == "Exp.1" | exp ==  "Exp.2" | exp== "Exp.3"))%>%
  gather(trial, look, fam1:test4) %>%
  mutate(trial_n = parse_number(trial)) %>%
  mutate(trial_type = str_extract(trial, "[a-z]+"))

fam$trial_type <- as.factor(fam$trial_type)
fam$trial_n <- as.factor(fam$trial_n)
fam$look <- as.numeric(as.character(fam$look))

famplot <- ggplot(data = fam, aes(trial_n, look, fill=trial_type))
famplot + geom_boxplot() +
  facet_wrap(~exp+trial_type, nrow=2)+
  xlab("Trial N")+
  stat_summary(fun.data =mean_cl_boot, geom="errorbar",width=0.1)+
    stat_summary(fun.y=mean,geom="point",shape=5)+
  ylab("Looking time (s)")+
  theme_cowplot(20)
```

**Figure S2.** Plot of looking times during familiarization across Experiments 1-4 (total N=`r length(unique(risk.avg$subj))`). 

## Including influential observations (reviewer suggestion)

Below, we report the results from all of our pre-registered analyses including all observations, rather than excluding influential observations.

```{r includingall.exp1}
exp1.everyone.table <- gen.m(exp1.1)
exp1.everyone.ci <- gen.ci(exp1.1)[3:4,]

exp1.everyone.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp1.avg)
exp1.everyone.betas <- gen.beta(exp1.everyone.beta)

exp1.everyone.results <- cbind(exp1.everyone.betas,exp1.everyone.table,exp1.everyone.ci)
```

```{r includingall.exp2}
exp2.everyone.test.table <- gen.m(exp2.1)
exp2.everyone.test.ci <- gen.ci(exp2.1)[3:4,]

exp2.everyone.test.beta <- lmer(scale(loglook)~ type + (1 | subj),
                                     data=exp2.avg)
exp2.everyone.test.betas <- gen.beta(exp2.everyone.test.beta)

exp2.everyone.test.results <- cbind(exp2.everyone.test.betas,exp2.everyone.test.table,exp2.everyone.test.ci)

exp2.everyone.pre.table <- gen.m(exp2.2)
exp2.everyone.pre.ci <- gen.ci(exp2.2)[3:4,]

exp2.everyone.pre.beta <- lmer(scale(loglook) ~ type + (1 | subj),
                                     data=exp2.control)
exp2.everyone.pre.betas <- gen.beta(exp2.everyone.pre.beta)

exp2.everyone.pre.results <- cbind(exp2.everyone.pre.betas,exp2.everyone.pre.table,exp2.everyone.pre.ci)

exp2.everyone.prevstest.table <- gen.m(exp2.3)
exp2.everyone.prevstest.ci <- gen.ci(exp2.3)[3:6,]

exp2.everyone.prevstest.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj), data = exp2.control.test)

exp2.everyone.prevstest.betas <- gen.beta(exp2.everyone.prevstest.beta)

exp2.everyone.prevstest.results <- cbind(exp2.everyone.prevstest.betas,exp2.everyone.prevstest.table,exp2.everyone.prevstest.ci)
```

```{r includingall.exp3}
exp3.everyone.test.table <- gen.m(exp3.1)
exp3.everyone.test.ci <- gen.ci(exp3.1)[3:4,]

exp3.everyone.test.beta <- lmer(scale(loglook)~ type + (1 | subj),
                                     data=exp3.avg)
exp3.everyone.test.betas <- gen.beta(exp3.everyone.test.beta)

exp3.everyone.test.results <- cbind(exp3.everyone.test.betas,exp3.everyone.test.table,exp3.everyone.test.ci)

exp3.everyone.pre.table <- gen.m(exp3.2)
exp3.everyone.pre.ci <- gen.ci(exp3.2)[3:4,]

exp3.everyone.pre.beta <- lmer(scale(loglook) ~ type + (1 | subj),
                                     data=exp3.control)
exp3.everyone.pre.betas <- gen.beta(exp3.everyone.pre.beta)

exp3.everyone.pre.results <- cbind(exp3.everyone.pre.betas,exp3.everyone.pre.table,exp3.everyone.pre.ci)

exp3.everyone.prevstest.table <- gen.m(exp3.3)
exp3.everyone.prevstest.ci <- gen.ci(exp3.3)[3:6,]

exp3.everyone.prevstest.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj), data = exp3.control.test)

exp3.everyone.prevstest.betas <- gen.beta(exp3.everyone.prevstest.beta)

exp3.everyone.prevstest.results <- cbind(exp3.everyone.prevstest.betas,exp3.everyone.prevstest.table,exp3.everyone.prevstest.ci)
```


### Experiment 1
Thirteen-month-old infants looked longer when the agent chose the target achieved through the lower-danger action  Thirteen-month-old infants looked longer when the agent chose the target achieved through the lower-danger action (Mlower=`r summary.1013$look[2]`s, Mhigher=`r summary.1013$look[1]`s, 95% confidence interval (CI) over difference in log seconds `r report(exp1.everyone.results,2,3,2)`). This looking preference is consistent with the interpretation that infants expected the agent to choose the target for which it had undertaken a more dangerous action and looked longer when this expected outcome did not occur. 

### Experiment 2
Ten-month-old infants did not show a statistically significant looking preference between the test events, (Mlower=`r summary.1013$look[4]`s, Mhigher=`r summary.1013$look[3]`s, `r report(exp2.everyone.results,2,3,1)`, mixed effect model with fixed effect of test event and random intercept for participant identity).

### Experiment 3
#### Collapsing across age groups
Across both age groups, infants looked longer at test when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[7]`s, Mshallow=`r summary.avg$look[8]`s, `r report(exp3.everyone.1013.test.results,2,3,1)`).

During the control events, infants showed a preference for the shallower trench in this context (Mdeep=`r summary.avg$look[5]`s, Mshallow=`r summary.avg$look[6]`s, `r report(exp3.everyone.1013.pre.results,2,3,2)`). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp3.everyone.1013.prevstest.results,4,3,2)`). Thus, infantsâ€™ expectations at test cannot be due to an intrinsic preference for events occurring over deeper to those over shallower trenches.

#### 13-month-olds
Thirteen-month-old infants looked longer at test when the agent, at test, chose the deeper trench over the shallower trench (Mdeep=`r summary.1013$look[11]`s, Mshallow=`r summary.1013$look[12]`s, `r report(exp3.everyone.13.test.results, 2, 3, 1)`, excluding one influential participant. During control events, 13-month-old infants preferred to look at the shallow trench (Mdeep=`r summary.1013$look[9]`s, Mshallow=`r summary.1013$look[10]`s, `r report(exp3.everyone.13.pre.results,2,3,2)`). Their looking preferences significantly differed across the two conditions, `r report(exp3.everyone.13.prevstest.results,4,3,2)`).

#### 10-month-olds
Ten-month-old looked marginally at test when the agent chose the deeper the shallower trench (Mdeep=`r summary.1013$look[7]`s, Mshallow=`r summary.avg$look[8]`s, `r report(exp3.everyone.10.test.results,2,3,1)`). During control events, 10-month-old infants displayed no looking preference (Mdeep=`r summary.1013$look[5]`s, Mshallow=`r summary.1013$look[6]`s, `r report(exp3.everyone.10.pre.results,2,3,2)`). In contrast to the data from the 13-month-old infants, however, these two patterns of looking preference did not differ from each other, `r report(exp3.everyone.10.prevstest.results,4,3,2)`.

### Experiment 4
Thirteen-month-old infants looked longer at test when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[11]`s, Mshallow=`r summary.avg$look[12]`s, `r report(exp4.everyone.results,2,3,1)`).

During the control events, infants showed a preference for the shallower trench in this context (Mdeep=`r summary.avg$look[9]`s, Mshallow=`r summary.avg$look[10]`s, `r report(exp.4.3.results.everyone,2,3,2)`). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp4.everyone.results2,4,3,2)`). This fully replicates Experiment 3.

### Experiment 5
Ten-month-old infants did not show a looking preference between events when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[15]`s, Mshallow=`r summary.avg$look[16]`s, `r report(exp5.everyone.results,2,3,1)`).

During the control events, infants again did not show a looking preference (Mdeep=`r summary.avg$look[13]`s, Mshallow=`r summary.avg$look[14]`s, `r report(exp.5.3.results.everyone,2,3,2)`). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp5.everyone.results2,4,3,2)`). 

Neither of these results are consistent with what we found in Experiment 3. 


## Order effects in Experiments 1 and 2 (reviewer suggestion)

### Experiment 1
```{r order.exp1}

exp1.order <- lmer(data = exp1.avg,
                   formula = loglook ~ first_fam * type + (1|subj))
exp1.order.table <- gen.m(exp1.order)
exp1.order.ci <- gen.ci(exp1.order)[3:6,]


exp1.order.betas <- lmer(data = exp1.avg,
                   formula = scale(loglook) ~ first_fam * type + (1|subj))
exp1.order.beta <- gen.beta(exp1.order.betas)

exp1.ordereffects <- cbind(exp1.order.table, exp1.order.beta, exp1.order.ci)

```

### Experiment 2
```{r order.exp2}

exp2.order <- lmer(data = exp2.avg,
                   formula = loglook ~ first_fam * type + (1|subj))
exp2.order.table <- gen.m(exp2.order)
exp2.order.ci <- gen.ci(exp2.order)[3:6,]


exp2.order.betas <- lmer(data = exp2.avg,
                   formula = scale(loglook) ~ first_fam * type + (1|subj))
exp2.order.beta <- gen.beta(exp2.order.betas)

exp2.ordereffects <- cbind(exp2.order.table, exp2.order.beta, exp2.order.ci)

```
Infants' looking preferences at test did not vary depending on which sequence of events (low to high danger vs high to low danger) they were randomly assigned to watch in the first familiarization trial (Experiment 1: `r report(exp1.ordereffects,4,3,2)`; Experiment 2: `r report(exp2.ordereffects,4,3,2)`). All infants saw 3 familiarization trials in each order.


## Power analysis over experiment 1
```{r exp1.power, eval=FALSE}
# sim <- powerCurve(extend(exp1.1, along="subj", n=500),
#                        along="subj", breaks = c(36, 40, 44, 48, 52, 56, 60, 64, 68), alpha = .05, seed = 123)
# plot(sim)
# print(sim)

```

## Power analysis over experiment 3
```{r exp3.power, eval=FALSE}
# sim2 <- powerCurve(extend(exp3.1, along="subj", n=500),
#                        along="subj", breaks = c(36, 40, 44, 48, 52, 56, 60, 64, 68), alpha = .05, seed = 123)
# plot(sim2)
# print(sim2)

```

## Generate Data for Reliability
```{r generate.rel, eval=FALSE}
# reliability <- wide %>% filter(reliability ==1) %>%
#   select(subj, sex, experiment, test1, test2, test3, test4) %>%
#   gather(trial, look, test1:test4) %>%
#   mutate(trialn = str_remove(trial, "test")) %>%
#   group_by(subj, trialn)
# write.csv(reliability, "risk_rel.csv")
```



# Bayes Factors
```{r}
library(bayestestR)

## no effect vs effect
bayesfactor_models(exp1.0, exp1.1, denominator = exp1.0) # Exp 1
bayesfactor_models(exp2.0, exp2.1, denominator = exp2.0) # Exp 2
bayesfactor_models(exp3a.0, exp3a.1, denominator = exp3a.0) # Exp 3 10mo
bayesfactor_models(exp3b.0, exp3b.1, denominator = exp3b.0) # Exp 3 13mo
bayesfactor_models(exp3.0, exp3.1, denominator = exp3.0) # Exp 3 13mo
```



