---
title: "Dangerous ground: One-year-old infants are sensitive to peril in other peopleâ€™s actions "
author: "Shari Liu"
date: "October 25, 2021"
output:
  html_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = "##", echo=FALSE, warning=FALSE, message=FALSE, cache=TRUE, include=TRUE, dependson="wide")
options(scipen = 0, digits = 3)

## load required packages
ipak <- function (pkg) {
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("multcomp", "lsmeans", "schoRsch", "influence.ME", "lme4", "effects", "lmerTest", "cowplot", "irr", "simr", "wesanderson", "patchwork", "janitor", "sjPlot", "corrplot", "dplyr", "tidyverse")

ipak(packages)

```

```{r prep.data}
detach("package:dplyr", unload = TRUE)
library(dplyr)

# read in data
wide <- read.csv(file = "peril_data_deid.csv", header = TRUE) 
head(wide)
str(wide)

# convert into long format
long <- gather(wide, type, look, testavg_lower:control_deep) 
str(long)

# log transform looks
long$look <- as.numeric(as.character(long$look))
long$loglook <- log(long$look)

# set levels for different kinds of looks
long$type <- factor(long$type)
#levels(long$type) <- c("Higher",
                       # "Lower", 
                       # "Deep (Control)",
                       # "Shallow (Control)",
                       # "Higher 1",
                       # "Higher 2",
                       # "Lower 1",
                       # "Lower 2",
                       # "Binary Pref",
                       # "Proportion Higher",
                       # "Proportion Lower")

# subset averaged looks across test pairs (2 observations per participant) and control events
long.avg <- long %>% 
  filter(type == "testavg_higher" | type == "testavg_lower" | type == "control_deep" | type =="control_shallow") %>%
  separate(type, into=c("phase", "type"), sep="_")%>%
  # add age groups (relevant for Experiments 1-3)
  mutate(agegroup = as.factor(case_when(agem < 12 ~ "younger",
                            agem > 12 ~ "older")))

long.avg$type <- factor(long.avg$type)
long.avg$phase <- factor(long.avg$phase)
long.avg$exp <- factor(long.avg$exp)


long.avg$sex <- relevel(as.factor(long.avg$sex), ref = "m")

exp1.avg <-dplyr::filter(long.avg, exp == "Exp.1")
exp2.avg <-dplyr::filter(long.avg, exp == "Exp.2")
exp3.avg <-dplyr::filter(long.avg, exp == "Exp.3")

risk.avg <- long.avg %>%
  filter(cost == "Risk",
         agegroup == "older") %>%
  mutate(task = as.factor(
    case_when(experiment == "RISK13" ~ "infer.value",
              (experiment == "MR13" | experiment == "MR2") ~ "min.risk")))

op <- options(contrasts = c("contr.treatment", "contr.poly")) # treatment contrasts
```

```{r prep.functions}
# function for identifying influential observations, and then returning a new model without them
# INPUTS: model = model name, data = dataset, and subj = column heading for observations
# OUTPUT: model excluding influential subjects
exclude.cooks <- function(model, data, subj) {
  cooks <- cooks.distance(influence(model, subj))
  cutoff <- 4/length(unique(data$subj))
  new.model <- exclude.influence(model, grouping = subj, level=data[which(cooks > cutoff),]$subj)
  return(new.model)
}

# function that computes CIs and returns them in df
gen.ci <- function(model) {
  df <- data.frame(confint(model))
  names(df) <- c("lower", "upper")
  return(df)
}

# function that converts model summary to df
gen.m <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "df", "t", "p")
  return(df)
}

# function that returns age info and number of females in a dataset, assuming 2 rows of data per subj
info <- function(longdata) {
  longdata %>% summarize(mean = mean(agem), min=range(agem)[1], max=range(agem)[2], f=sum(sex=="f")/2, n=length(unique(subj)))
}

## Retrieved from : http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/#error-bars-for-within-subjects-variables
## Gives count, mean, standard deviation, standard error of the mean, and confidence interval (default 95%).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   groupvars: a vector containing names of columns that contain grouping variables
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=TRUE,
                      conf.interval=.95, .drop=TRUE) {
  library(plyr)
  
  # New version of length which can handle NA's: if na.rm==T, don't count them
  length2 <- function (x, na.rm=FALSE) {
    if (na.rm) sum(!is.na(x))
    else       length(x)
  }
  
  # This does the summary. For each group's data frame, return a vector with
  # N, mean, and sd
  datac <- ddply(data, groupvars, .drop=.drop,
                 .fun = function(xx, col) {
                   c(N    = length2(xx[[col]], na.rm=na.rm),
                     mean = mean   (xx[[col]], na.rm=na.rm),
                     sd   = sd     (xx[[col]], na.rm=na.rm)
                   )
                 },
                 measurevar
  )
  
  # Rename the "mean" column    
  datac <- plyr::rename(datac, c("mean" = measurevar))
  
  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
  
  # Confidence interval multiplier for standard error
  # Calculate t-statistic for confidence interval: 
  # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
  ciMult <- qt(conf.interval/2 + .5, datac$N-1)
  datac$ci <- datac$se * ciMult
  
  return(datac)
}
## Norms the data within specified groups in a data frame; it normalizes each
## subject (identified by idvar) so that they have the same mean, within each group
## specified by betweenvars.
##   data: a data frame.
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   na.rm: a boolean that indicates whether to ignore NA's
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=TRUE, .drop=TRUE) {
  library(plyr)
  
  # Measure var on left, idvar + between vars on right of formula.
  data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                         .fun = function(xx, col, na.rm) {
                           c(subjMean = mean(xx[,col], na.rm=na.rm))
                         },
                         measurevar,
                         na.rm
  )
  
  # Put the subject means with original data
  data <- merge(data, data.subjMean)
  
  # Get the normalized data in a new column
  measureNormedVar <- paste(measurevar, "_norm", sep="")
  data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
    mean(data[,measurevar], na.rm=na.rm)
  
  # Remove this subject mean column
  data$subjMean <- NULL
  
  return(data)
}

## Summarizes data, handling within-subjects variables by removing inter-subject variability.
## It will still work if there are no within-S variables.
## Gives count, un-normed mean, normed mean (with same between-group mean),
##   standard deviation, standard error of the mean, and confidence interval.
## If there are within-subject variables, calculate adjusted values using method from Morey (2008).
##   data: a data frame.
##   measurevar: the name of a column that contains the variable to be summariezed
##   betweenvars: a vector containing names of columns that are between-subjects variables
##   withinvars: a vector containing names of columns that are within-subjects variables
##   idvar: the name of a column that identifies each subject (or matched subjects)
##   na.rm: a boolean that indicates whether to ignore NA's
##   conf.interval: the percent range of the confidence interval (default is 95%)
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=TRUE, conf.interval=.95, .drop=TRUE) {
  
  # Ensure that the betweenvars and withinvars are factors
  factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                       FUN=is.factor, FUN.VALUE=logical(1))
  
  if (!all(factorvars)) {
    nonfactorvars <- names(factorvars)[!factorvars]
    message("Automatically converting the following non-factors to factors: ",
            paste(nonfactorvars, collapse = ", "))
    data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
  }
  
  # Get the means from the un-normed data
  datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                     na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Drop all the unused columns (these will be calculated with normed data)
  datac$sd <- NULL
  datac$se <- NULL
  datac$ci <- NULL
  
  # Norm each subject's data
  ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
  
  # This is the name of the new column
  measurevar_n <- paste(measurevar, "_norm", sep="")
  
  # Collapse the normed data - now we can treat between and within vars the same
  ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                      na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
  
  # Apply correction from Morey (2008) to the standard error and confidence interval
  #  Get the product of the number of conditions of within-S variables
  nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                  FUN.VALUE=numeric(1)))
  correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
  
  # Apply the correction factor
  ndatac$sd <- ndatac$sd * correctionFactor
  ndatac$se <- ndatac$se * correctionFactor
  ndatac$ci <- ndatac$ci * correctionFactor
  
  # Combine the un-normed means with the normed results
  merge(datac, ndatac)
}

# function that returns ICC 
reporticc <- function(output, places) {
  mainstat <- output$value
  upperci <- output$ubound
  lowerci <- output$lbound
  statistic <- paste("ICC=", round(mainstat,places), ", 95% CI [", round(lowerci, places), ", ", round(upperci, places), "]", sep = "")
  return(statistic)
}

# function that returns column of standardized betas from lmer model
gen.beta <- function(model) {
  f <- data.frame(fixef(model))
  colnames(f) <- "beta"
  return(f)
}

# function that computes CIs and returns them in df
gen.ci <- function(model) {
  df <- data.frame(confint(model))
  names(df) <- c("lower", "upper")
  return(df)
}

# function that converts model summary (lmer) to df
gen.m <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "df", "t", "p")
  return(df)
}

# function that converts model summary (lm) to df
gen.lm <- function(model) {
  df <- data.frame(coef(summary(model)))
  names(df) <- c("est", "se", "t", "p")
  return(df)
}

# function that returns APA-formatted result from lme4/lmerTest table
report <- function(table, index, places, tails, flip) {
  if (tails == "1") {
    p <- round(table$p[index], places)/2
    howmanytails <- "one-tailed"
  } else {
    p <- round(table$p[index], places)
    howmanytails <- "two-tailed"
  }
  if (p < .001) {
    p <- "<.001"
  } else {
    p <- paste("=", round(p, places), sep = "")
  }
  if (missing(flip)) {
    result <- paste("[", round(table$lower[index], places), ",", round(table$upper[index], places), "], ÃŸ=", round(table$beta[index], places), ", B=", round(table$est[index],places), ", SE=", round(table$se[index],places), ", p", p, ", ", howmanytails, sep = "")
  } else {
    result <- paste("[", -round(table$upper[index], places), ",", -round(table$lower[index], places), "], ÃŸ=", -round(table$beta[index], places), ", B=", -round(table$est[index],places), ", SE=", round(table$se[index],places), ", p", p, ", ", howmanytails, sep = "")
  }
  return(result)
}
```

```{r summary}
## get within-subjects CIs for plotting

# warning about Nan has to do with missing observations for control events
summary.avg <- summarySEwithin(data = risk.avg, measurevar = "look", betweenvars = c("exp", "phase"), withinvars = "type", idvar = "subj") %>%
  drop_na() %>%  
  mutate(cliff = type)
levels(summary.avg$cliff) <- c("deep", "deep", "shallow", "shallow")
levels(summary.avg$phase) <- c("control", "test")

```

```{r ntrialsexcluded}

# figure out how many looks are missing from the dataframe
nexclude <- wide %>%
   gather(type, look, control_1:test4) %>%
   filter(cost=="Risk") %>%
   mutate(missing = case_when(is.na(look) | str_detect(look, "NA") ~ 1)) %>%
   group_by(exp) %>%
   count(missing) %>%
  filter(!is.na(missing)) %>%
  rename(n_missing = n) %>%
  select(!missing)

totaltrials <- wide %>%
   gather(type, look, control_1:test4) %>%
   filter(cost=="Risk",
          !is.na(experiment)) %>%
   group_by(exp) %>%
   tally() %>%
   rename(total = n)

ntrials <- full_join(nexclude, totaltrials)
```

## Reliability + Distribution Info
```{r reliability}

rel <- read.csv(file = "peril_reliability_deid.csv", header=TRUE)
exp1 <- rel %>% filter(experiment.new=="Exp.1")
exp2 <- rel %>% filter(experiment.new=="Exp.2")
exp3 <- rel %>% filter(experiment.new=="Exp.3")

exp1rel <- icc(data.frame(exp1$secondary.look, exp1$orig.look),model="one", type="agreement")

exp2rel <- icc(data.frame(exp2$secondary.look, exp2$orig.look),model="one", type="agreement")

exp3rel <- icc(data.frame(exp3$secondary.look, exp3$orig.look),model="one", type="agreement")

```

```{r log, include = TRUE}
normal.ll <- fitdistr(na.omit(risk.avg$look), "normal")$loglik
lognormal.ll <- fitdistr(na.omit(risk.avg$look), "lognormal")$loglik
```

# Figures
```{r fig.exp1, include=TRUE, fig.width=4}

theme_set(theme_cowplot(font_size=20))

exp1.fig.data <- risk.avg %>% filter(task == "infer.value",
                                           phase == "testavg")
levels(exp1.fig.data$type) <- c(NA, "higher", "lower", NA)
exp1.fig.data$type <- relevel(exp1.fig.data$type, ref = "higher")
colors1 <- c(wes_palettes$Zissou1[3], wes_palettes$Zissou1[2])

risk1 <- ggplot(data = exp1.fig.data %>% filter(exp=="Exp.1"), aes(type, look, fill = type))+
  geom_boxplot()+
  scale_fill_manual(values=colors1)+
    geom_errorbar(data = summary.avg %>% filter(exp =="Exp.1"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  ylab("Looking Time (s)") +
  xlab("Test event") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  theme(legend.position="none")+
  scale_x_discrete(labels = c("higher\nvalue", "lower\nvalue"))
  # annotate("text", colour="red", x=1.5, y=63, size=5, label=c("*ÃŸ=0.354", "ÃŸ=0.168")) +
  # facet_wrap(~exp, scales = "fixed", drop=TRUE)
  # theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

risk1
```

**Figure 2.** Looking time towards the test events in Experiment 2. 

```{r fig.exp2, include=TRUE, fig.width=8, fig.height=8}

theme_set(theme_cowplot(font_size=20))

exp23.figure <- rbind(exp2.avg,exp3.avg) %>%
  filter(agegroup == "older") %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))
exp23.figure$cliff <- as.factor(exp23.figure$cliff)
exp23.figure$cliff <- relevel(exp23.figure$cliff, ref = "shallow")
exp23.figure$phase <- as.factor(exp23.figure$phase)

levels(exp23.figure$cliff)
levels(exp23.figure$phase) <- c("control", "test")
exp23.colors <- c(wes_palette("Royal2")[2], wes_palette("Royal2")[1])

exp2.figure <- ggplot(data = exp23.figure %>% filter(exp == "Exp.2"), aes(cliff, look, fill = cliff)) +
  geom_boxplot(aes(alpha=phase))+
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  geom_errorbar(data = summary.avg %>% filter(exp == "Exp.2"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  ylab("Looking Time (s)") +
  xlab("Cliff Depth") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  facet_wrap(~phase, nrow=1)+
  theme(legend.position="none")+
  scale_fill_manual(values = exp23.colors)+
  scale_alpha_discrete(range=c(0.4, 1))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

exp3.figure <- ggplot(data = exp23.figure %>% filter(exp == "Exp.3"), aes(cliff, look, fill = cliff)) +
  geom_boxplot(aes(alpha=phase))+
  stat_summary(fun.y = mean, alpha = 0.8, geom = "point", shape=21, size=3, position = "dodge", colour = "red", fill = "red") +
  geom_errorbar(data = summary.avg %>% filter(exp == "Exp.3"), colour="red", position = position_dodge(width = 5), width = 0, aes(ymin=look-ci, ymax=look+ci)) +
  ylab("Looking Time (s)") +
  xlab("Cliff Depth") +
  coord_cartesian(ylim = c(0, 65)) +
  geom_point(alpha = 0.1)+
  geom_line(alpha = 0.2, aes(group = subj))+
  facet_wrap(~phase, nrow=1)+
  theme(legend.position="none")+
  scale_fill_manual(values = exp23.colors)+
  scale_alpha_discrete(range=c(0.4, 1))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))



exp2.figure + exp3.figure + plot_annotation(tag_levels = 'A')

```

**Figure 4.**  Looking times from Experiments 2 (A, in-lab) and 3 (B, online) during the control events (lighter) and the test events (darker).


# Experiment 1: Inferring value from risk

```{r exp1.primary}
exp1.avg$type <- relevel(exp1.avg$type, ref = "higher")


exp1.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp1.avg)

exp1.1 <- lmer(loglook ~ type + (1|subj),
               data = exp1.avg)

# id influential observations
plot(influence(exp1.1, "subj"), which="cook",
     cutoff=4/32, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")

exp1.1.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp1.avg %>% filter(subj != "S4_12"))

exp1.1.table <- gen.m(exp1.1)
exp1.1.ci <- gen.ci(exp1.1)[3:4,]

exp1.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp1.avg)
exp1.1.betas <- gen.beta(exp1.1.beta)

exp1.results <- cbind(exp1.1.table, exp1.1.betas,exp1.1.ci)


```

## Methods

### Participants
Our final sample of participants included N=`r info(exp1.avg)$n` 13-month-old infants (M=`r info(exp1.avg)$mean` months, range=`r info(exp1.avg)$min`-`r info(exp1.avg)$max`, `r info(exp1.avg)$f` female).  Seven infants were excluded and replaced due to fussiness (3 infants) or inattentiveness during test trials (4 infants). Participants were recruited through a database of families who expressed interest in cognitive development research in the Boston Area. Of the families in this database who chose to provide demographic information, 79.5% identified their children as White, 10.2% as Asian, 6.9% as Other, 2.5% as Black or African American, 0.4% as American Indian/Alaska Native, and 0.4% as Native Hawaiian/Pacific Islander; 90.3% as not Hispanic or Latino, 9.5% as Hispanic or Latino, and 0.2% as both. 90.4% of children had at least one parent or legal guardian with a college diploma or higher. All data were collected at the Harvard Lab for Developmental Studies with procedures approved by the Committee on the Use of Human Subjects. We chose to study 13-month-old infants, instead of 10-month-old infants (the age group we focused on in past research) (Liu et al., 2017) due both to constraints on our participant resources at the time, and due to the fact that 13-month-old infants have more experience with standing, walking, and falling: experiences that may be important for the development of these abilities. The sample size was chosen based on a simulation power analysis over the confirmatory analyses from 2 previous experiments with very similar structure (though these studies were conducted with 10-month-old infants: Experiments 1-2 from Liu et al., 2017), and we collected data until we attained our pre-specified N. The full pre-registration document, including full details about methods, sample size, hypotheses, and analysis plan, is accessible at https://osf.io/bs3e7/.


### Data Coding and Analysis Strategy.
Infant looking times were coded online using XHAB (Pinto, 1995), and offline using Datavyu (Datavyu Team, 2014). All experimenters and coders were naive to the nature and the order of the test events and were unable to see what the babies saw during the experiment (they relied on trial-neutral sound cues to start each trial). To check for exclusions and coding errors, all test trial data were re-coded in Datavyu and excluded as necessary: If an infant looked away from a test event without ever having seen the agent jump, or if the trial ended too early or late, that trial was marked and excluded from subsequent analysis (`r ntrials$n_missing[2]` out of `r ntrials$total[2]` total test trials). We used these offline coded looking times for our final analyses. To assess the reliability of the data, 50% of test trials from the experiment (`r ntrials$total[2]/2` out of `r ntrials$total[2]` trials) were re-coded Datavyu by an additional researcher who was naive to test event order. Reliability was high, `r reporticc(exp1rel,3)`.  All decisions to include or exclude trials or participants from our analysis were made by researchers who were blind to the events seen by infants.

Infant looking times are often log-normally distributed (Csibra, Hernik, Mascaro, Tatone, & Lengyel, 2016), including in this dataset (log-likelihood of data for Experiments 1-3 under normal distribution = `r normal.ll`, under lognormal distribution = `r lognormal.ll`), so our pre-registered dependent measure was the average looking time towards the higher- or lower-danger choice at test in log seconds, and the values of unstandardized B coefficients and 95% confidence intervals are reported in this unit. Nevertheless, we include summary statistics and plots of untransformed looking times for interpretability. We analyzed all looking times using mixed effects models (Bates et al., 2015) implemented in R. All analyses including repeated measures included a random intercept for participant identity. Analyses conducted over multiple experiments included a random intercept for experiment, except in one case where including this intercept led to issues with model convergence. For every model, we checked for influential participants using Cookâ€™s Distance (Nieuwenhuis et al., 2012) and excluded any participants who exceeded the standard 4/n threshold, where n is the number of participants. The number of participants who met this criterion is listed in every model result, and including vs excluding these observations does not change the interpretation of any of our primary analyses. For results including all observations, see SOM. 


## Results
### Pre-registered results.
We compared infantsâ€™ looking times when the agent approached the target for which it performed the more dangerous action (Higher Value) to the looking times when the agent approached the other target (Lower Value). Thirteen-month-old infants looked longer when the agent chose the target achieved through the less dangerous action (Mlower=`r summary.avg$look[2]`s, Mhigher=`r summary.avg$look[1]`s, pooled standard error (SE)=`r summary.avg$se[1]`), 95% confidence interval (CI) over difference in log seconds `r report(exp1.results,2,3,2)` excluding one influential participant). This finding is consistent with the interpretation that infants expected the agent to choose the target for which it had undertaken a more dangerous action, and they looked longer when this expected outcome did not occur.

# Experiment 2: Minimizing Risk
```{r exp2.primary}

exp2.test <- exp2.avg %>% filter(phase=="testavg") 

exp2.info <- info(exp2.avg)

exp2.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp2.test)

exp2.1 <- lmer(loglook ~ type + (1|subj),
               data = exp2.test)

# id influential observations
plot(influence(exp2.1, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# one influential observation

exp2.1.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp2.test %>% filter(subj != "24-MR"))
exp2.1.table <- gen.m(exp2.1.cooks)
exp2.1.ci <- gen.ci(exp2.1.cooks)[3:4,]

exp2.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp2.test %>% filter(subj != "24-MR"))
exp2.1.betas <- gen.beta(exp2.1.beta)

exp2.results <- cbind(exp2.1.table, exp2.1.betas, exp2.1.ci)
```

```{r exp2.pre}
exp2.control <- exp2.avg %>% filter(phase=="control") 

exp2.2 <- lmer(loglook ~ type + (1|subj),
               data = exp2.control)

# id influential observations
plot(influence(exp2.2, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# two influential observation

exp2.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp2.control %>% filter(subj != "59-MR" & subj != "54-MR"))

exp2.table <- gen.m(exp2.cooks)
exp2.ci <- gen.ci(exp2.cooks)[3:4,]

exp2.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp2.control %>% filter(subj != "59-MR" & subj != "54-MR"))
exp2.betas <- gen.beta(exp2.beta)

exp2.results2 <- cbind(exp2.table, exp2.betas, exp2.ci)
```

```{r exp2.pre.vs.test}
exp2.control.test <- exp2.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))

  
exp2.control.test$type <- as.factor(exp2.control.test$type)

exp2.3 <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp2.control.test)

plot(influence(exp2.3, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# 1 influential observation

exp2.3.cooks <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp2.control.test)

exp2.3.table <- gen.m(exp2.3)
exp2.3.ci <- gen.ci(exp2.3)[3:6,]

exp2.3.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj),
                     data = exp2.control.test)
exp2.3.betas <- gen.beta(exp2.3.beta)

exp2.results3 <- cbind(exp2.3.table,exp2.3.betas,exp2.3.ci)
```

## Methods
### Participants
Our final sample of participants included `r exp2.info$n` 13-month-old infants (M=`r exp2.info$mean` months, range=`r exp2.info$min`-`r exp2.info$max`, `r exp2.info$f` female) We chose this sample size using a power analysis from a pilot study, as well as estimates of effect sizes of studies with similar displays and design (Liu & Spelke, 2017; Liu et al., 2017). We collected data until we attained our pre-specified N. Infants were excluded and replaced in the final sample due to fussiness that prevented study completion (3 infants), inattentiveness during test trials (2 infants), or interference from caregivers (2 infants). Our pre-registration document is available and open access at https://osf.io/efc3g/.

### Data Coding and Analysis
The data coding and analysis strategy for Experiment 3 were identical to those of Experiments 1 and 2. Twenty-five out of `r ntrials$total[3]` total trials (4 test trials and 2 control trials per participant) were excluded from the analysis based on inattentiveness or coding error. To assess the reliability of the data, 50% of test trials from the experiment (60 of 120 total test trials) were re-coded Datavyu by an additional researcher who was naive to test event order. Reliability was high, `r reporticc(exp2rel,3)`.

## Results
Important note: In this paper, we report the results of a study originally pre-registered with a sample including both 10-month-old and 13-month-old infants. Because our investigation with 10-month-old infants is still ongoing, we deviate from our pre-registration by reporting only results from the older age group. Data from both age groups are open access at https://osf.io/kz7br/. 

Thirteen-month-old infants looked longer at test when the agent, at test, chose to cross the deeper trench over the shallower trench (Mdeep=`r summary.avg$look[5]`s, Mshallow=`r summary.avg$look[6]`s, pooled SE=`r summary.avg$se[6]`, `r report(exp2.results,2,3,1)`, excluding one influential participant). See Figure 4A.

 To test whether this looking preference reflected the relative danger of the different jumps, or other perceptual features of the shallow and deep trenches, we compared infantsâ€™ looking times during the control events, where their attention was drawn to each trench using an attention-getting star that was placed in the path of the agentâ€™s subsequent actions. During control events, 13-month-old infants preferred to look at events near the shallow trench (Mdeep=`r summary.avg$look[3]`s (SE=`r summary.avg$se[3]`), Mshallow=`r summary.avg$look[4]`s (SE=`r summary.avg$se[4]`), `r report(exp2.results2,2,3,2)`, excluding 2 influential participants). Infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp2.results3,4,3,2)`). See Figure 4A.

# Experiment 3: Minimizing risk replication (no shattering)


```{r exp3.test}

exp3.control.test <- exp3.avg %>%
  mutate(cliff = case_when(type=="deep" | type =="higher" ~ "deep",
                           type=="shallow" | type =="lower" ~ "shallow"))

exp3.avg <- exp3.avg %>% filter(phase=="testavg") 

exp3.info <- info(exp3.avg)

exp3.0 <- lmer(loglook ~ 1 + (1|subj),
               data = exp3.avg)

exp3.1 <- lmer(loglook ~ type + (1|subj),
               data = exp3.avg)

# id influential observations
plot(influence(exp3.1, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# no influential observations

exp3.1.table <- gen.m(exp3.1)
exp3.1.ci <- gen.ci(exp3.1)[3:4,]

exp3.1.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp3.avg)
exp3.1.betas <- gen.beta(exp3.1.beta)

exp3.results <- cbind(exp3.1.table, exp3.1.betas, exp3.1.ci)
```

```{r exp3.pre}
exp3.control <- exp3.control.test %>% filter(phase=="control") 

exp3.2 <- lmer(loglook ~ type + (1|subj),
               data = exp3.control)

# id influential observations
plot(influence(exp3.2, "subj"), which="cook",
     cutoff=4/42, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# two influential observation

exp3.2.cooks <- lmer(loglook ~ type + (1|subj),
               data = exp3.control %>% filter(subj != "26" & subj != "28"))

exp3.2.table <- gen.m(exp3.2.cooks)
exp3.2.ci <- gen.ci(exp3.2.cooks)[3:4,]

exp3.2.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp3.control %>% filter(subj != "26" & subj != "28"))
exp3.2.betas <- gen.beta(exp3.2.cooks)

exp3.results2 <- cbind(exp3.2.table, exp3.2.betas, exp3.2.ci)
```


```{r exp3.pre.vs.test}

  
exp3.control.test$type <- as.factor(exp3.control.test$type)

exp3.3 <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp3.control.test)

plot(influence(exp3.3, "subj"), which="cook",
     cutoff=4/30, sort=TRUE,
     xlab="CookÂ´s Distance",
     ylab="Subject ID")
# 1 influential observation

exp3.3.cooks <- lmer(loglook ~ cliff * phase + (1|subj),
                     data = exp3.control.test %>% filter(subj != "28"))

exp3.3.table <- gen.m(exp3.3.cooks)
exp3.3.ci <- gen.ci(exp3.3.cooks)[3:6,]

exp3.3.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj),
                     data = exp3.control.test %>% filter(subj != "28"))
exp3.3.betas <- gen.beta(exp3.3.beta)

exp3.results3 <- cbind(exp3.3.table,exp3.3.betas,exp3.3.ci)
```

```{r pairwise}
# probably should have pre-registered this instead of 2 separate models
pairwise0 <- lsmeans(exp3.3.cooks, list(pairwise~cliff|phase)) 

pairwise.beta <- lsmeans(exp3.3.beta, list(pairwise~cliff|phase)) 

pairwise.beta.value <- pairwise.beta[[2]] %>% as.data.frame() %>% select(contrast, phase, estimate) %>%
  rename(beta = estimate)

pairwise.CI <- confint(pairwise0[[2]]) %>% as.data.frame()

pairwise.t.p <- pairwise0[[2]] %>% as.data.frame()

within.exp3.almost <- full_join(pairwise.CI, pairwise.t.p) %>%
  rename(est = estimate,
         se = SE,
         lower = lower.CL,
         upper = upper.CL,
         t = t.ratio,
         p = p.value)

within.exp3 <- full_join(pairwise.beta.value, within.exp3.almost)
```

```{r other.info.exp3}
wide %>%
  filter(exp == "Exp.3") %>%
  tabyl(device)

wide %>%
  filter(exp == "Exp.3") %>%
  tabyl(highchair)

wide %>%
  filter(exp == "Exp.3") %>%
  summarise(vquality = mean(video_quality, na.rm=TRUE),
            vquality.sd = sd(video_quality, na.rm=TRUE),
            aquality = mean(audio_quality, na.rm=TRUE),
            aquality.sd = sd(audio_quality, na.rm=TRUE))

```

## Methods
### Participants
Our final sample consisted of `r exp3.info$n` 12- to 15-month-old infants (M=`r exp3.info$mean` months, range=`r exp3.info$min`-`r exp3.info$max`, `r exp3.info$f` female). We chose a slightly wider age range relative to Experiment 2 to enable more rapid online participant recruitment. We recruited participants both from our lab database, as in Experiments 1-2, and through Children Helping Science (https://childrenhelpingscience.com/). We chose this sample size based on a simulation power analysis over infantsâ€™ looking preferences towards the test events from Experiment 2. A total of 6 infants were excluded and replaced in the final sample (3 due to technical issues, 2 due to inattentiveness and 1 due to interference from the caregiver).  Our pre-registration document is available at https://osf.io/96qsf/. Our pre-registered target sample size was N=40, and our stopping rule was to stop recruiting as soon as we reached our target N, but to finish collecting data if we accidentally over-recruited. Thus, our final sample was N=42.


### Procedure
Whereas Experiments 1-2 were conducted in a quiet, dark room in a lab setting, Experiment 3 was conducted over Zoom, in infantsâ€™ homes, due to the COVID-19 pandemic. As in Experiments 1-2, all procedures were approved by the Committee on the Use of Human Subjects at Harvard University. We used materials developed by the Stanford Social Learning Lab (Social Learning Lab, 2020) to introduce caregivers to the online testing setup and to ask for verbal consent. Caregivers also provided written consent prior to the study session. Whereas infants in Experiments 1-2 sat on their caregiversâ€™ laps and watched our displays on a large projector screen, infants in Experiment 3 sat in a high chair (25 out of 42 participants) or their caregiversâ€™ laps (17/42), depending on familiesâ€™ preferences, and watched the displays on a tablet (8/42) or a laptop computer (34/42). We provided caregivers with instructions, both before and during the study, to minimize distractions (pets, people walking by, and distracting objects) during the study session. 

To maximize the quality of the events seen by infants, we shared our stimuli with caregivers through YouTube playlists. We then controlled the caregiverâ€™s screen using Zoomâ€™s remote control feature, and coded looking times during the study using jHab (Casstevens 2007). Then, we double checked for trial exclusions and generated the final data from the recording of the session video using Datavyu (Datavyu Team 2014). After the session, caregivers rated the quality of the audio and video on a 5-point Likert scale (1 = very poor; 5 = very good). Caregivers, on average, gave high ratings for both (video: M=4.88, SD=0.34; audio: M=4.85, SD=0.36). Because the experimenter did not know which YouTube playlist included which videos, and only had access to the video feed of infantsâ€™ faces (and not the stimuli) during the experiment, they were unaware of the order of test events. Because we did not want to prevent caregivers from stopping or intervening at home in case of a safety issue, we did not ask caregivers to close their eyes, and instead sat them behind their infants (for high-chair sessions), and instructed them to refrain from directing their infantsâ€™ attention towards and away from the screen. See SOM for our online testing protocol. 

#### Data Coding and Analysis
The data coding and analysis strategy for Experiment 3 were identical to those from Experiment 2. Fifty-three out of `r ntrials$total[4]` total trials (including familiarization, test, and control trials) were excluded from analysis because of inattentiveness, distractions at home (e.g. pet noises, people walking by), technical issues and coding errors. We note that the proportion of excluded trials (10.5%) was higher than what we observed in the lab in Experiment 2 (5.56%), likely due to a combination of reasons, including: distractions in the home environment, the smaller size of the screen displaying the videos at home, and lower quality and more variable video feeds of the infantsâ€™ faces (which could lead to more trial mis-timings).  To assess the reliability of the data, 50% of test trials from the experiment (84 of 168 test trials) were re-coded Datavyu by an additional researcher who was also unaware of the order of test events. Interrater reliability was high, `r reporticc(exp3rel,3)`.

## Results
### Pre-registered results
We fully replicated the two key results from Experiment 2. First, infants looked longer at test when the agent chose to jump the deeper trench than when the agent chose to jump the shallower trench (Mdeep=`r summary.avg$look[9]`s, Mshallow=`r summary.avg$look[10]`s, pooled SE=`r summary.avg$se[10]`, `r report(exp3.results,2,3,1, flip)`, no influential participants). Second, infantsâ€™ looking preferences between the control events and the test events significantly differed from each other (`r report(exp3.results3, 4, 2, 3)`, excluding 1 inlufential participant). 

### Exploratory results
During the control events, infants showed a numerical but non-significant preference for the shallower trench in this context (Mdeep=`r summary.avg$look[7]`s, Mshallow=`r summary.avg$look[8]`s, pooled SE=`r summary.avg$se[8]`, `r report(exp3.results2, 2, 3, 2)`, excluding 2 influential participants). See Figure 4A.

# Supplemental Online Materials

```{r logplot}
# is a lognormal transformation justified given the distribution of looks?
fig.S1 <- ggplot(data = risk.avg, aes(look, fill=exp))
fig.S1 +
  geom_density(alpha = 0.5)+
  # geom_text(aes(experiment))+
  theme_cowplot(20)+
  # facet_wrap(~exp)+
  xlab("Looking Time (s)")
  # scale_fill_brewer(palette="Set2")
```

**Figure S1.** Density plot of looking times during test for Experiments 1-3 (total N=`r length(unique(risk.avg$subj))`) from test events and control events. Maximum-likelihood fitting revealed that the lognormal distribution (log likelihood=`r lognormal.ll`) provides a better fit to these data than the normal distribution (log likelihood=`r normal.ll`).

```{r famplot}
fam <- wide %>%
  filter(cost=="Risk",
         (exp == "Exp.1" | exp ==  "Exp.2" | exp== "Exp.3"))%>%
  gather(trial, look, fam1:test4) %>%
  mutate(trial_n = parse_number(trial)) %>%
  mutate(trial_type = str_extract(trial, "[a-z]+"))

fam$trial_type <- as.factor(fam$trial_type)
fam$trial_n <- as.factor(fam$trial_n)
fam$look <- as.numeric(as.character(fam$look))

famplot <- ggplot(data = fam, aes(trial_n, look, fill=trial_type))
famplot + geom_boxplot() +
  facet_wrap(~exp+trial_type, nrow=2)+
  xlab("Trial N")+
  stat_summary(fun.data =mean_cl_boot, geom="errorbar",width=0.1)+
    stat_summary(fun.y=mean,geom="point",shape=5)+
  ylab("Looking time (s)")+
  theme_cowplot(20)
```

**Figure S2.** Plot of looking times during familiarization across Experiments 1-4 (total N=`r length(unique(risk.avg$subj))`). 

## Including influential observations (reviewer suggestion)

Below, we report the results from all of our pre-registered analyses including all observations, rather than excluding influential observations.

```{r includingall.exp1}
exp1.everyone.table <- gen.m(exp1.1)
exp1.everyone.ci <- gen.ci(exp1.1)[3:4,]

exp1.everyone.beta <- lmer(scale(loglook) ~ type + (1|subj),
               data = exp1.avg)
exp1.everyone.betas <- gen.beta(exp1.everyone.beta)

exp1.everyone.results <- cbind(exp1.everyone.betas,exp1.everyone.table,exp1.everyone.ci)
```

```{r includingall.exp2}
exp2.everyone.test.table <- gen.m(exp2.1)
exp2.everyone.test.ci <- gen.ci(exp2.1)[3:4,]

exp2.everyone.test.beta <- lmer(scale(loglook)~ type + (1 | subj),
                                     data=exp2.avg)
exp2.everyone.test.betas <- gen.beta(exp2.everyone.test.beta)

exp2.everyone.test.results <- cbind(exp2.everyone.test.betas,exp2.everyone.test.table,exp2.everyone.test.ci)

exp2.everyone.pre.table <- gen.m(exp2.2)
exp2.everyone.pre.ci <- gen.ci(exp2.2)[3:4,]

exp2.everyone.pre.beta <- lmer(scale(loglook) ~ type + (1 | subj),
                                     data=exp2.control)
exp2.everyone.pre.betas <- gen.beta(exp2.everyone.pre.beta)

exp2.everyone.pre.results <- cbind(exp2.everyone.pre.betas,exp2.everyone.pre.table,exp2.everyone.pre.ci)

exp2.everyone.prevstest.table <- gen.m(exp2.3)
exp2.everyone.prevstest.ci <- gen.ci(exp2.3)[3:6,]

exp2.everyone.prevstest.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj), data = exp2.control.test)

exp2.everyone.prevstest.betas <- gen.beta(exp2.everyone.prevstest.beta)

exp2.everyone.prevstest.results <- cbind(exp2.everyone.prevstest.betas,exp2.everyone.prevstest.table,exp2.everyone.prevstest.ci)
```

```{r includingall.exp3}
exp3.everyone.test.table <- gen.m(exp3.1)
exp3.everyone.test.ci <- gen.ci(exp3.1)[3:4,]

exp3.everyone.test.beta <- lmer(scale(loglook)~ type + (1 | subj),
                                     data=exp3.avg)
exp3.everyone.test.betas <- gen.beta(exp3.everyone.test.beta)

exp3.everyone.test.results <- cbind(exp3.everyone.test.betas,exp3.everyone.test.table,exp3.everyone.test.ci)

exp3.everyone.pre.table <- gen.m(exp3.2)
exp3.everyone.pre.ci <- gen.ci(exp3.2)[3:4,]

exp3.everyone.pre.beta <- lmer(scale(loglook) ~ type + (1 | subj),
                                     data=exp3.control)
exp3.everyone.pre.betas <- gen.beta(exp3.everyone.pre.beta)

exp3.everyone.pre.results <- cbind(exp3.everyone.pre.betas,exp3.everyone.pre.table,exp3.everyone.pre.ci)

exp3.everyone.prevstest.table <- gen.m(exp3.3)
exp3.everyone.prevstest.ci <- gen.ci(exp3.3)[3:6,]

exp3.everyone.prevstest.beta <- lmer(scale(loglook) ~ cliff * phase + (1|subj), data = exp3.control.test)

exp3.everyone.prevstest.betas <- gen.beta(exp3.everyone.prevstest.beta)

exp3.everyone.prevstest.results <- cbind(exp3.everyone.prevstest.betas,exp3.everyone.prevstest.table,exp3.everyone.prevstest.ci)
```


### Experiment 1
Thirteen-month-old infants looked longer when the agent chose the target achieved through the lower-danger action  Thirteen-month-old infants looked longer when the agent chose the target achieved through the lower-danger action (`r report(exp1.everyone.results,2,3,2)`). This looking preference is consistent with the interpretation that infants expected the agent to choose the target for which it had undertaken a more dangerous action and looked longer when this expected outcome did not occur. 

### Experiment 2
Infants looked longer at test when the agent, at test, chose the deeper trench over the shallower trench (`r report(exp2.everyone.test.results, 2, 3, 1)`. During control events, 13-month-old infants preferred to look at the shallow trench(`r report(exp2.everyone.pre.results,2,3,2)`). Their looking preferences significantly differed across the two phases of the experiment, `r report(exp2.everyone.prevstest.results,4,3,2)`).

### Experiment 3
Infants looked longer at test when the agent, at test, chose the deeper trench over the shallower trench (`r report(exp3.everyone.test.results, 2, 3, 1)`, excluding one influential participant. During control events, infants did not show a strong preference for either event (`r report(exp3.everyone.pre.results,2,3,2)`). Their looking preferences significantly differed across the two phases of the experiment, `r report(exp3.everyone.prevstest.results,4,3,2)`). This fully replicates the two key findings from Experiment 2: longer looking at test towards the action over the deep trench, and a different pattern of looking than to control events.

## Order effects in Experiment 1 (reviewer suggestion)
```{r order.exp1}

exp1.order <- lmer(data = exp1.avg,
                   formula = loglook ~ first_fam * type + (1|subj))
exp1.order.table <- gen.m(exp1.order)
exp1.order.ci <- gen.ci(exp1.order)[3:6,]


exp1.order.betas <- lmer(data = exp1.avg,
                   formula = scale(loglook) ~ first_fam * type + (1|subj))
exp1.order.beta <- gen.beta(exp1.order.betas)

exp1.ordereffects <- cbind(exp1.order.table, exp1.order.beta, exp1.order.ci)

```

Infants' looking preferences at test did not vary depending on which sequence of events (low to high danger vs high to low danger) they were randomly assigned to watch in the first familiarization trial (`r report(exp1.ordereffects,4,3,2)`). All infants saw 3 familiarization trials in each order.

## Differences in attention for 4 familiarization movies, Exp 1

```{r}
exp1.fam <- read.csv("./exp1_fam_csvs/exp1_fam_looks.csv", header=TRUE)

exp1.fam <- exp1.fam %>%
  separate(videoclip, into = c("depth", "yesno"), remove=FALSE) %>%
  rename(subj= subjID)

exp1.fam$depth <- as.factor(exp1.fam$depth)
exp1.fam$yesno <- as.factor(exp1.fam$yesno)
exp1.fam$trial <- as.factor(exp1.fam$trial)
exp1.fam$subj <- as.factor(exp1.fam$subj)
exp1.fam$videoclip <- as.factor(exp1.fam$videoclip)

exp1.fam.glancedoff <- exp1.fam %>%
  mutate(glanced.off = case_when(proportion.on == 1.0 ~ 0,
                                proportion.on < 1.0 ~ 1))

exp1.fam.glancedoff.totalclips <- exp1.fam.glancedoff %>%
  select(subj, depth, videoclip, glanced.off) %>%
  group_by(subj, videoclip) %>%
  summarise(totalclips = n()) 

exp1.fam.glancedoff.freq <- exp1.fam.glancedoff %>%
  select(subj, depth, videoclip, glanced.off) %>%
  group_by(subj, videoclip) %>%
  tally(glanced.off)

exp1.fam.glanced.off.summary <- full_join(exp1.fam.glancedoff.totalclips, exp1.fam.glancedoff.freq) %>%
  mutate(prop.glancedoff = n/totalclips) %>%
  mutate(depth = case_when(videoclip == "deep_no" ~ "deep",
                           videoclip == "shallow_yes" ~ "shallow",
                           videoclip == "medium_no" ~ "medium",
                           videoclip == "medium_yes" ~ "medium"))

exp1.fam.glanced.off.summary$videoclip <- factor(exp1.fam.glanced.off.summary$videoclip, levels=c("shallow_yes", "medium_no", "medium_yes", "deep_no"))
```

```{r}

figS4.individual <- exp1.fam.glanced.off.summary %>%
  ggplot(aes(videoclip, prop.glancedoff, fill=depth)) + 
  geom_boxplot() +
  geom_point(alpha=0.3) +
  geom_line(alpha = 0.2, aes(group = subj)) +
  ylab("Proportion of events including look away") +
  xlab("Event type") +
  # facet_wrap(~depth) + 
  stat_summary(fun.data =mean_cl_boot, geom="errorbar",width=0.2)+
    stat_summary(fun=mean,geom="point",shape=5, size=3)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

figS4.individual
```

```{r}

```


```{r}
# compute 4 values per subject, total proportion to
# deep_no, medium_yes, medium_no, shallow_yes
exp1.fam.bymovie <- exp1.fam %>%
  group_by(subj,videoclip, depth, yesno) %>%
  mutate(proportion.on.total = mean(proportion.on)) %>%
  distinct(proportion.on.total)

exp1.fam.bymovie.wide <- exp1.fam.bymovie %>%
  pivot_wider(names_from = videoclip, values_from = proportion.on.total, id=subj)

exp1.avg.diff <- exp1.avg %>%
  filter(phase == "testavg") %>%
  pivot_wider(names_from = type, values_from = look, id=subj) %>%
  mutate(delta.look = lower-higher)

exp1.fam.glancedoff.wide <- exp1.fam.glanced.off.summary %>%
  pivot_wider(names_from = videoclip, values_from = prop.glancedoff, id=subj)

exp1.famtest <- full_join(exp1.fam.bymovie.wide, exp1.avg.diff, by=c("subj")) %>% 
  na.omit()
exp1.famtest.long <- exp1.famtest %>%
  gather(key = "movie_clip", value = "proportion_looking", shallow_yes:deep_no)

exp1.famtest.glanceoff <- full_join(exp1.fam.glancedoff.wide, exp1.avg.diff, by=c("subj")) %>% 
  na.omit()

exp1.famtest.glanceofflong <- exp1.famtest.glanceoff %>%
  gather(key = "movie_clip", value = "proportion_glanced_off", shallow_yes:deep_no)

```

```{r}
theme_set(theme_cowplot(font_size=15))


figS3.individual <- exp1.fam.bytrial %>%
  ggplot(aes(videoclip, proportion.on, fill=depth)) + 
  geom_boxplot() +
  geom_point(alpha=0.3) +
  # geom_line(alpha = 0.2, aes(group = subjID)) +
  ylab("Proportion of looking relative \n to length of video clip") +
  xlab("Video clip") +
  # facet_wrap(~depth) + 
  stat_summary(fun.data =mean_cl_boot, geom="errorbar",width=0.2)+
    stat_summary(fun=mean,geom="point",shape=5, size=3)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), legend.position = "none") +
    ggtitle('All video clips')

figS3.avg <- exp1.fam.bymovie %>%
  ggplot(aes(videoclip, proportion.on.total, fill=depth)) + 
  geom_boxplot() +
  geom_point(alpha = 0.3) +
  # geom_line(alpha = 0.2, aes(group = subjID)) +
  # facet_wrap(~depth) + 
  stat_summary(fun.data =mean_cl_boot, geom="errorbar",width=0.2)+
    stat_summary(fun=mean,geom="point",shape=5, size=3)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1), axis.title.x=element_blank(), axis.title.y=element_blank()) +
    ggtitle('Averaged within subjects')


(figS3.individual + figS3.avg) + plot_annotation(tag_levels = 'A')
```

*Figure S3.* Proportion of time that infants looked towards the screen during each familiarization video clip, relative to the duration of each clip, (A) over all clips, or (B) averaged within subjects. Data came from a random subset of infants in Experiment 1 (N=16 out of 32 total infants). Error bars represent bootstrapped 95% confidence intervals around the mean.

```{r}
theme_set(theme_cowplot(font_size=15))

figS4A <- 
exp1.famtest.long %>%
  ggplot(aes(proportion_looking, delta.look)) + 
  geom_point() +
  geom_smooth(method="lm") +
  # geom_line(alpha = 0.2, aes(group = subjID)) +
  xlab("Total proportion looking \n to movie clip") +
  ylab("Looking preference at test (s)\n
       <--- Longer looking to expected ---- Longer looking to unexpected --->") +
  facet_wrap(~movie_clip)

figS4A
```

*Figure S4A. [not in final paper?]* Scatter plot of average proportion looking to each movie clip from familiarization and looking preferences at test. 


```{r}
cor.data <- exp1.famtest.glanceoff %>%
  select(shallow_yes:deep_no, delta.look) %>%
  rename(VOE_response = delta.look) %>%
  as.data.frame() 


corrplot(cor(cor.data[,-1]),
         method='circle',
         type='lower',
         addCoef.col ='black',
         diag=FALSE)
```

*Figure S4.* Correlation plot relating infants' lookaway behavior for each event type (proportion of events that infants glanced away from), to each other, and to infants' violation of expectation response (unexpected - expected) at test. Values indicate Pearson's correlations.


```{r}
fam.glance1 <- lmer(data = exp1.fam.glanced.off.summary,
               formula = prop.glancedoff ~ videoclip + (1|subj))
summary(fam.glance1)
tab_model(fam.glance1)
plot(allEffects(fam.glance1))
```

```{r}

fam.glance2 <- lm(data = exp1.famtest.glanceoff,
             formula = scale(delta.look) ~ scale(shallow_yes) + scale(medium_no) + scale(medium_yes) + scale(deep_no))
tab_model(fam.glance2)
summary(fam.glance2)
plot(allEffects(fam.glance2))
```

```{r}

fam1 <- lmer(data = exp1.fam.bymovie,
               formula = proportion.on.total ~ videoclip + (1|subj))
summary(fam1)
tab_model(fam1)
plot(allEffects(fam1))
```

```{r}

fam2 <- lm(data = exp1.famtest,
             formula = scale(delta.look) ~ scale(shallow_yes) + scale(medium_no) + scale(medium_yes) + scale(deep_no))
tab_model(fam2)
summary(fam2)
plot(allEffects(fam2))
```


<!-- ## Power analysis over experiment 1 -->
```{r exp1.power, eval=FALSE}
# sim <- powerCurve(extend(exp1.1, along="subj", n=500),
#                        along="subj", breaks = c(36, 40, 44, 48, 52, 56, 60, 64, 68), alpha = .05, seed = 123)
# plot(sim)
# print(sim)

```


<!-- ## Generate Data for Reliability -->
```{r generate.rel, eval=FALSE}
# reliability <- wide %>% filter(reliability ==1) %>%
#   select(subj, sex, experiment, test1, test2, test3, test4) %>%
#   gather(trial, look, test1:test4) %>%
#   mutate(trialn = str_remove(trial, "test")) %>%
#   group_by(subj, trialn)
# write.csv(reliability, "risk_rel.csv")
```



